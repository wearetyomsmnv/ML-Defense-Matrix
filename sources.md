# Список источников

1. MITRE ATLAS Framework, https://atlas.mitre.org/
2. MITRE ATLAS Fact Sheet, https://atlas.mitre.org/pdf-files/MITRE_ATLAS_Fact_Sheet.pdf
3. MITRE ATLAS Techniques, https://atlas.mitre.org/techniques
4. ArXiv LLM Security Survey, https://arxiv.org/html/2505.01177v1
5. Nature Scientific Reports - Adversarial Defense, https://www.nature.com/articles/s41598-024-56259-z
6. NCSC Machine Learning Principles, https://www.ncsc.gov.uk/collection/machine-learning-principles
7. ISACA AI Security Best Practices, https://www.isaca.org/resources/news-and-trends/industry-news/2024/ai-security-risk-and-best-practices
8. Understanding Generative AI Attacks with MITRE ATLAS, https://medium.com/@tahirbalarabe2/understanding-generative-ai-based-attacks-with-mitre-atlas-a4e3be2a26e6
9. Securing LLMs - A MITRE ATLAS Playbook, https://medium.com/@adnanmasood/securing-large-language-models-a-mitre-atlas-playbook-5ed37e55111e
10. Prompt Injection Defenses Repository, https://github.com/tldrsec/prompt-injection-defenses
11. Adversarial Robustness Toolbox, https://github.com/Trusted-AI/adversarial-robustness-toolbox
12. Awesome AI Security, https://github.com/ottosulin/awesome-ai-security
13. HiddenLayer, https://hiddenlayer.com/
14. Protect AI, https://protectai.com/
15. Prompt Security, https://www.prompt.security/

